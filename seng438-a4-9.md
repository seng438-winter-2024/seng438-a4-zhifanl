**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group: 9   |
|-----------------|
| Student 1 Zhifan Li        |   
| Student 2 Sandip Mishra              |   
| Student 3 Shanzi Ye             |   
| Student 4 Fardin Aryan      

# Introduction

This lab report focuses on the exploration and understanding of two key testing methodologies: Mutation Testing and GUI Testing, applied to a selected website. The first segment of the assignment required students to delve into the intricacies of Mutation Testing. This involved the use of a tool known as PIT Mutations to introduce mutation faults into a Java code-base. The task was to interpret the mutation scores reported and analyze the mutants that were either killed or survived. This analysis was then used to devise new test cases aimed at enhancing the overall efficacy of the test suite. The second part of the assignment revolved around GUI Testing of a chosen website. This was accomplished through a prevalent approach to GUI test automation known as record and replay. The exercise provided an opportunity to learn and apply Selenium, a widely recognized tool for web interface testing, and compare its performance with other alternatives.

# Analysis of 10 Mutants of the Range class 

**Tested Method:**


public boolean intersects(double b0, double b1) 

**Tested Line in the Method:**

if (b0 <= this.lower)


**Raised Mutants:**


`1. Changed Conditional Boundary → SURVIVED`

This mutation likely changed b0 <= this.lower to b0 < this.lower or b0 > this.lower.

Since this mutation survived, it indicates that there was no test case specifically testing the boundary condition of b0 being exactly equal to this.lower. However, considering the provided test cases, it's surprising this mutant survived, as several test cases should cover boundary conditions.

`2. Negated Conditional → KILLED`

Negating b0 <= this.lower would cause the method's logic to change significantly.

It was killed, meaning at least one test case failed due to this change, which indicates good test coverage for the conditional logic's true and false paths.

`3. Removed Conditional - Replaced Comparison Check with False → SURVIVED`

This mutation makes the conditional always false, likely causing the method to always evaluate the else branch.

Its survival indicates a lack of test coverage for scenarios where b0 is less than or equal to this.lower.

`4. Removed Conditional - Replaced Comparison Check with True → KILLED`

By always making the condition true, the first branch is always executed.

This mutant being killed indicates that there are sufficient tests covering the case where b0 is less than or equal to this.lower.

`5. Negated Double Local Variable Number 1 → KILLED`

There's no direct mention of a double local variable being negated in the method provided, but if such a mutation occurred and was killed, it suggests the tests are sensitive to the value changes in the method's calculations.

`6. Negated Double Field Lower → SURVIVED`

Negating this.lower would impact how ranges are evaluated.

Its survival suggests that tests may not fully cover scenarios involving the lower bound of the range, especially edge cases.

`7-10, & 12-18. Various Comparison and Increment/Decrement Mutations → Mixed Outcomes`

Mutations involving changing comparison operators and incrementing or decrementing variables had mixed outcomes, with most being killed. This indicates a generally good level of test coverage for these operations, though the survival of some mutants (e.g., changing to >= or mutations on double field lower) suggests potential gaps in testing edge cases or specific boundary conditions.

`11. Greater Than to Not Equal → SURVIVED`

This suggests the tests might not differentiate between > and != effectively, possibly overlooking scenarios where values are exactly equal but not considered overlapping.

`19. Decremented (--a) Double Field Lower → SURVIVED`

Similar to other mutations on this.lower, its survival suggests insufficient testing around the lower bound values.



# Report all the statistics and the mutation score for each test class

## Range.java(Oringinal) 


![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/fdf9fcf2-74b1-42ee-8a4d-26e7f191dae6)


## Range.java(Updated) 

![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/07a283b5-c9e1-4784-a6db-c0b4f28297c2)

## DataUtilities.java(Original) 

![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/b8398d26-0350-44ba-b4ab-d2448e19594b)



## DataUtilities.java(Updated) 


![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/1e0a6e74-391a-4a6a-9132-6f76dab4f826)


# Analysis drawn on the effectiveness of each of the test classes

# A discussion on the effect of equivalent mutants on mutation score accuracy

In order to find flaws and potential improvement areas in our test suites, mutation testing is an essential technique for assessing their efficacy. The existence of comparable mutants, on the other hand—mutants that do not modify the program's exterior behavior—posed a serious problem for us. Because these mutations are intrinsically undetected by any test case, they could produce deceptive mutation scores, which is an issue for the accuracy of mutation scores.

After learning about the effects of identical mutants, we were aware of how crucial it was to thoroughly examine the mutants that survived and make the distinction between the equivalent mutants and those that survived because of inadequate test coverage. Finding similar mutations is a difficult undertaking that frequently calls for in-depth knowledge of both the consequences of the mutants and the functioning of the code. By concentrating on significant enhancements to our test suite and minimizing needless efforts on unkillable mutants, we aim to improve our mutation testing procedure through this lab.

# A discussion of what could have been done to improve the mutation score of the test suites

The mutation coverage, which was established based on the tests we developed in labs 2 and 3, allowed us to create highly effective test suites for both the Range and DataUtilities classes. With DataUtilities nearing 81% mutation coverage, it was a difficult task to significantly enhance the coverage due to the presence of non-applicable or equivalent mutants. However, we scrutinized the mutation summaries for the statements and adopted a reverse-engineering approach to try and augment the coverage for DataUtilities. Finally, we increased the mutation score by 11 percent. A similar strategy was employed for Range to eradicate some of the surviving mutants. We tested the oringinal rangetest.java and got a 58% mutation score. We carefully looked at the result and see which mutants haven't been killed. Then we look at these alive mutants and made some test cases to kill them. Finally, we increaseed the mutation score by 12%.   In future, this same methodology can potentially be utilized to eliminate more mutants, thereby improving the mutation score.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is essential for evaluating the quality of our test suites and their effectiveness in identifying errors. By making small changes (mutations) to the software, we can test whether the current test suite can detect these changes, thereby assessing the suite's ability to catch errors.

## Advantages and Disadvantages of Mutation Testing


Mutation testing offers a powerful method for improving the quality and effectiveness of test suites in identifying errors. However, its practical application requires careful consideration of its potential drawbacks, including time, computational resources, and the handling of equivalent mutants. By addressing these challenges, development teams can leverage mutation testing to significantly enhance their software testing processes.

| Aspect                 | Advantages                                                                                     | Disadvantages                                                                                  |
|------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|
| **Automation**         | Mutation testing is automated, reducing the need for manual intervention.                      | The process can be time-intensive, potentially slowing down the development process.           |
| **Quality Assessment** | Provides a mutation score, indicating test suite quality and when to cease testing.           | The presence of equivalent mutants, which the test suite cannot detect, poses a challenge.     |
| **Error Identification** | Enhances the ability to identify hidden errors by testing the test suite's error detection capabilities. | Requires significant computational resources, which may not be feasible for all projects. |
| **Test Suite Improvement** | Encourages the improvement of the test suite's coverage and effectiveness.                   | May produce false positives, requiring additional analysis to identify valid issues.          |











# Explain your SELENUIM test case design process
## Shanzi Ye
Shanzi tested two main features on the eBay website: Providing Feedback and Getting Help. These tests simulate common user interactions with the site, verifying the functionality and user experience for feedback submission and help information retrieval.

| Feature              | Description                                                   |
|----------------------|---------------------------------------------------------------|
| Providing Feedback   | Tests the user's ability to provide feedback through the eBay website's feedback form. This includes opening the feedback form, selecting a rating, entering feedback text, and submitting the feedback. |
| Getting Help         | Tests the user's ability to search for help topics through the eBay Help and Contact page. This includes navigating to the Help page, entering search terms, executing the search, and verifying the results. |

## Zhifan Li
Zhifan conducted Selenium automated tests on the eBay website, focusing on user authentication, search functionality, and account management. These tests are designed to simulate common user interactions, such as logging in with valid credentials, searching for items using specific keywords, viewing item details, and logging out. 

| Feature                                         | Description                                                                                                 |
|-------------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| Login With  Credentials                    | Tests the user's ability to log in using valid credentials, including navigating to the sign-in page and entering user details. |
| Search With Keywords and View First Item  | Extends the search test by selecting and viewing the first item in the search results, verifying item details. |


## Sandip Mishra

Sandip tested the search bar functionality in various scenarios and the language change feature. These tests simulate user interactions to verify the search functionality with different inputs and the ability to change the website's language setting.

| Feature                             | Description                                                                |
|-------------------------------------|----------------------------------------------------------------------------|
| Search Bar Functionality            | Tests the search bar with different keywords, including large queries and no queries, ensuring accurate results are displayed. |
| Language Change Feature             | Verifies the functionality of changing the site's language setting, ensuring the site remains functional after language switches. |


## Fardin Aryan

Fardin focused on features that enhance user navigation and access: shopping by category and changing the country settings. 

| Feature                               | Description                                                                 |
|---------------------------------------|-----------------------------------------------------------------------------|
| Shop by Category with Subcategory     | Verifies the user's ability to navigate eBay’s inventory by selecting various categories and subcategories. |
| Change Country to Different Country   | Tests the functionality of the eBay site to switch to a different country version, checking for appropriate content changes. |




# Explain the use of assertions and checkpoints

Assertions are used in the scenarios we covered for eBay to confirm the final state following activities like product searches and language changes on the website. For instance, we claim that the keyword "ipad" shows in the search results heading after typing the word into the search box and clicking search, indicating the search was carried out successfully. In a similar vein, we verify that the word "支援及聯絡" (Support and Contact) is there when we switch the country option to Taiwan, indicating that the site's content has been changed to reflect the language of the chosen nation. These checkpoints are essential for verifying that every test phase yields the desired outcome, therefore guaranteeing that the functionality of the application satisfies the required specifications.

# how did you test each functionaity with different test data

## Shanzi Ye
| Test Functionality             | Scenario                                   | Description |
|--------------------------------|---------------------------------------------|-------------|
| Providing Feedback             | Positive feedback text                      | Tests the functionality of the feedback form by entering positive text to simulate a satisfied user experience. |
| Providing Feedback             | No feedback text (empty parameters)         | Verifies that the feedback form handles empty submissions correctly and provides appropriate feedback to the user. |
| Providing Feedback             | All empty parameters                        | Checks the behavior of the feedback submission when all fields are left empty, ensuring error handling and validation work. |
| Getting Help with Specifics    | Query with specific keywords ("Stolen Items") | Assesses the help section's search functionality by looking up terms related to specific issues, confirming the relevancy of search results. |
| Getting Help without Parameters| No search query                             | Tests the default state and response of the help section when no query is entered. |
| Getting Help with Random Text  | Random alphanumeric string                  | Evaluates the search function's handling of random, irrelevant input, testing the system's robustness against unexpected or non-standard queries. |

## Zhifan Li
| Functionality                             | Scenario                                  | Description |
|-------------------------------------------|-------------------------------------------|-------------|
| Login With Valid Credentials              | Normal login process                      | Validates the user's ability to log in with valid credentials using eBay's standard login flow, including optional sign-in with Google. |
| Login and Skip Additional Authentication  | Skipping optional authentication steps    | Tests the login flow when the user opts to skip additional authentication options like Google sign-in. |
| Verify Successful Login                   | Confirming user identity after login      | Ensures that after login, the system correctly displays the user's identity, confirming a successful sign-in. |
| Search With Valid Keywords                | Performing a search with common keywords  | Verifies the search functionality by entering common search terms and assessing the presence of search results. |
| Viewing First Item From Search Results    | Detailed view of a search result          | After a search, tests the functionality of viewing detailed information for the first item listed in the search results. |
| Verify Listing Details                    | Confirming details of a listed item       | Ensures that the details of a listed item, such as title and options, are present and correct. |
| Logout With Valid Credentials             | Normal logout process                     | Confirms the user's ability to log out properly and verifies the correct response of the website upon logout. |

## Sandip Mishra
| Functionality                         | Scenario                                          | Description |
|---------------------------------------|---------------------------------------------------|-------------|
| Search Bar Functionality              | Searching for a specific item (iPad)              | Verifies the search bar's ability to find items using a specific keyword and checks if the results are relevant. |
| Search with Large Query               | Attempting a search with an extensive query       | Tests the search bar's response to a large search query and whether it handles it gracefully without showing results. |
| Search with No Query                  | Triggering a search without entering any keywords | Examines how the search functionality behaves when no search terms are provided and ensures no irrelevant results are shown. |
| Language Change Interface             | Switching the interface language to French        | Confirms that the language change functionality works correctly and that the interface updates to reflect the new language choice. |
| Language Change, Search, and Revert   | Performing a search after a language change       | Checks if the search feature works correctly after the interface language has been changed and then reverts the language to English to validate consistency. |


## Fardin Aryan
| Functionality                              | Scenario                                  | Description |
|--------------------------------------------|-------------------------------------------|-------------|
| Shop by Category with Subcategory          | Navigating to a subcategory (Antiques)    | Confirms the site's navigation through categories and subcategories, and verifies the page title and breadcrumb trail for accuracy. |
| Shop by Category with Main Category        | Browsing a main category (Collectibles & Art) | Checks the functionality of shopping by main categories and ensures that relevant page titles and category descriptions appear. |
| Change Country to Different Country        | Changing the site's country to Taiwan     | Tests the ability to switch to a different country's version of the site and checks for the corresponding language and support link updates. |
| Change Country to the Same Country         | Selecting the same country (Canada)       | Ensures the site does not redirect or change unnecessarily when selecting the country version that is already active. |

# Discuss advantages and disadvantages of Selenium vs. Sikulix

Both Selenium and SikuliX are popular tools in the automation testing landscape, each offering unique advantages and facing certain limitations. Below is a comparison to help understand their strengths and weaknesses.

## Selenium

Selenium is widely used for automating web browsers, providing a robust framework for testing web applications across different browsers and platforms.

### Advantages and Disadvantages

| Aspect             | Advantages                                                                 | Disadvantages                                                 |
|--------------------|----------------------------------------------------------------------------|---------------------------------------------------------------|
| **Support**        | Extensive cross-platform and cross-browser support.                        | Limited to the testing of web applications only.              |
| **Versatility**    | Highly versatile for web testing scenarios.                               |                                                               |
| **Community**      | Large community support and extensive documentation.                       |                                                               |

## SikuliX

SikuliX leverages visual recognition to automate actions on both web and desktop applications, making it useful for a variety of testing scenarios beyond traditional web testing.

### Advantages and Disadvantages

| Aspect                 | Advantages                                                                                  | Disadvantages                                                        |
|------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------------------------|
| **Capability**         | Can automate Flash objects, providing a unique advantage.                                   | Faces challenges with cross-browser testing.                        |
| **Utility**            | Extends automation capabilities to desktop applications, broadening its utility.            |                                                                      |
| **Versatility**        | Useful for scenarios where traditional object identification fails.                         |                                                                      |

## Conclusion

Selenium and SikuliX offer different sets of features that cater to various testing needs. Selenium's strength lies in its extensive support for web application testing across a multitude of browsers and platforms. On the other hand, SikuliX's ability to automate Flash objects and desktop applications provides a broader scope of testing beyond web applications. However, the choice between Selenium and SikuliX should be based on the specific requirements of the testing project, considering the advantages and limitations of each tool.
# How the team work/effort was divided and managed
Our team prioritized equitable workload distribution and active collaboration for this assignment. Each member contributed significantly, ensuring a balanced effort across the board. Below is a detailed breakdown of our work division:

## Work Distribution

### Part 1: Enhancing Mutation Scores and Reporting

- **Group 1: Shanzi and Fardin**: Tasked with improving the mutation score of `RangeTest.java`. Group 1's responsibilities also include drafting the associated report, detailing the strategies employed and the outcomes achieved.

- **Group2: Zhifan and Sandip**: Focused on elevating the mutation score of `DataUtility.java`. Similar to their group 1, group 2 are also in charge of composing the report related to their task, encompassing both the methodology used and the results obtained.

### Part 2: Case Testing Requirements

- As per assignment requirements, each team member was required to test at least two cases. Adhering to this guideline, everyone successfully executed two case tests, demonstrating our collective commitment to fulfilling the project requirements comprehensively.





# Difficulties encountered, challenges overcome, and lessons learned

We had several difficulties when working on Lab 4, mostly related to comprehending the objectives of the task and preparing the PITest environment. One of the biggest obstacles was the ambiguous directions, which made it difficult to understand and took a lot of time to complete the job. Further impeding our work were technical issues with PITest, which sometimes prevented it from producing summaries and necessitated several restarts. Our time was mostly taken up by these problems, which hindered our productivity and made it harder for us to comprehend the lab activities.In spite of these challenges, we worked on the assignment and figure out the solution. We discovered the value of perseverance and cooperation and this assignment improves our troubleshooting abilities.

# Comments/feedback on the lab itself

Our understanding and proficiency in software testing were enhanced by the insightful experience of the Web App and Mutation Testing Lab. Although it is a little difficult at first due to a lack of thorough instructions, working with PIT Mutation and Selenium turned out to be immensely informative. One of the best parts of the lab was working as a team to overcome the more challenging parts. We enjoyed the process even though we had to deal with some challenging situations that put our comprehension to the test. In the future, a greater range of examples, better beginning support, and more detailed instructions would all significantly improve the lab's learning experience.
