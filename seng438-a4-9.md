**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group: 9   |
|-----------------|
| Student 1 Zhifan Li        |   
| Student 2 Sandip Mishra              |   
| Student 3 Shanzi Ye             |   
| Student 4 Fardin Aryan      

# Introduction

This lab report talks about looking into two main ways of testing: Mutation Testing and GUI Testing, and we used them on a specific website. In the first part, we explored Mutation Testing. We used a tool called PIT Mutations to add faults to Java code. Our job was to understand the mutation scores and look at which mutants were stopped or kept going. From this, we created new tests to make our testing better. The second part was about GUI Testing on a website we picked. We did this using a popular method called Selenium. This part let us learn how to use Selenium, a tool known for testing web interfaces, and see how it stacks up against others.

# Analysis of 10 Mutants of the Range class 

| Mutation ID | Line | Mutation Description | Detailed Analysis | Result |
|-------------|------|----------------------|-------------------|--------|
| 1 | 176 | Replaced boolean return with false | This mutation changes the intersects method so it always says `false’, pretending no ranges cross over, no matter where they are or how long they are. When this mutation is labled as "KILLED", it shows our testing can spot very small mistakes—even those that completely change what a method is supposed to do, like checking if ranges overlap. This makes sure our program can correctly find when ranges overlap, which is very important for features that rely on comparing ranges. | KILLED |
| 2 | 176 | Replaced boolean return with true | By always returning `true`, this mutation falsely suggests that all ranges intersect, regardless of their actual relation to each other. The ability of our tests to kill this mutation demonstrates the suite's robustness in identifying overly permissive behaviors, safeguarding against false positives in intersection detection. This level of sensitivity is crucial for applications where accurate detection of range overlap determines functionality or outcomes. | KILLED |
| 3 | 176 | Removed call to `getLowerBound` | Removing the call to `getLowerBound` disrupts the method's ability to accurately assess the starting point of a range, potentially leading to incorrect intersection reports. The killing of this mutation indicates that our test suite is finely tuned to verify the integral components of the intersection logic, ensuring that both boundaries of a range are considered. This mutation highlights the importance of comprehensive boundary testing in software that manipulates or compares data ranges. | KILLED |
| 4 | 176 | Removed call to `getUpperBound` | This mutation tests the impact of ignoring the upper boundary in determining range intersections. The fact that it was killed signifies that our tests are designed to consider the complete span of a range, from start to end, validating the essential nature of the upper bound in accurate intersection logic. It emphasizes the necessity of considering every aspect of range data to maintain integrity in functionalities that depend on range comparisons. | KILLED |
| 5 | 176 | Removed call to `intersects` | By eliminating the intersection logic entirely, this mutation directly challenges the core functionality of the `intersects` method. Its detection and subsequent killing by our test suite affirm the suite's comprehensive coverage and its ability to ensure that fundamental functionalities, such as determining if two ranges intersect, are correctly implemented and protected against removal or degradation. | KILLED |
| 6 | 176 | Replaced return of integer sized value with (x == 0 ? 1 : 0) | This mutation introduces a conditional return value based on the original method's outcome, significantly altering the method's logic in a manner that could indirectly affect the intersection results. The killing of this mutation underscores the precision of our testing suite in identifying and reacting to changes that might not directly relate to the method in question but could influence its correctness or the accuracy of its outputs. This showcases the depth of our testing strategy, extending beyond direct method functionality to include related computational logic. | KILLED |
| 7| 189 | Negated conditional | This mutation inverts the condition within the `if` statement in the `constrain` method, which checks if the input value falls outside the range, needing adjustment to either the upper or lower bound. Negating this conditional could result in unnecessary adjustments for values already within the range, compromising the method's functionality. The fact that this mutation was killed reflects well on our test suite's ability to ensure values are correctly adjusted only when necessary, preserving the method's integrity. | KILLED |
| 8 | 189 | Removed call to `contains` | Removing the call to `contains` bypasses the initial check to see if the value is within the range, directly impacting the decision logic for adjusting the value. Its survival indicates a potential oversight in our testing, specifically the suite's capacity to verify that no adjustment occurs for values already within the range, highlighting a critical area for improvement in our tests. | SURVIVED |
| 9 | 189 | Removed conditional - replaced equality check with false | By replacing a conditional check with false, this mutation prevents the method from ever adjusting values that are outside the range, effectively disabling a key functionality of the `constrain` method. The mutation being killed demonstrates our tests' effectiveness in catching failures to adjust out-of-range values back into the range, ensuring the method fulfills its purpose. | KILLED |
| 10 | 189 | Removed conditional - replaced equality check with true | Similar to the first mutation but in the opposite direction, making the conditional always true could lead to unnecessary adjustments for values that are already within the acceptable range. The survival of this mutation points to a gap in our testing, particularly in identifying when the method improperly adjusts values that do not require it. This suggests a need for more targeted tests to capture such erroneous behavior. | SURVIVED |




# Report all the statistics and the mutation score for each test class

## Range.java(Oringinal) 


![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/fdf9fcf2-74b1-42ee-8a4d-26e7f191dae6)


## Range.java(Updated) 

![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/110203582/647e7cd8-1cc1-4e3c-b796-b8fde7d87851)


## DataUtilities.java(Original) 

![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/b8398d26-0350-44ba-b4ab-d2448e19594b)



## DataUtilities.java(Updated) 


![method](https://github.com/seng438-winter-2024/seng438-a4-zhifanl/assets/114043815/1e0a6e74-391a-4a6a-9132-6f76dab4f826)


# Analysis drawn on the effectiveness of each of the test classes
## 

Range.java: After we tested the file file from Assignmet 3, we got a 58 mutation score, which was not ideal. Then we added a bunch of test cases to kill the alive mutants. AFter that we increased the mutation score by 10%. The updated rangetest.java has a 68% mutation score.

DataUtilities.java: After we tested the file file from Assignmet 3, we got a 81 mutation score, which was already perfect. Then we added a bunch of test cases to kill the remaining alive mutants. AFter that we increased the mutation score by 11%. The updated rangetest.java has a 92% mutation score. 

# A discussion on the effect of equivalent mutants on mutation score accuracy

In order to find flaws and potential improvement areas in our test suites, mutation testing is an essential technique for assessing their efficacy. The existence of comparable mutants, on the other hand—mutants that do not modify the program's exterior behavior—posed a serious problem for us. Because these mutations are undetected by any test case, they could produce deceptive mutation scores, which is an issue for the accuracy of mutation scores.

After learning about the effects of identical mutants, we were aware of how crucial it was to thoroughly examine the mutants that survived and make the distinction between the equivalent mutants and those that survived because of inadequate test coverage. Finding similar mutations is a difficult undertaking that frequently calls for in-depth knowledge of both the consequences of the mutants and the functioning of the code. By concentrating on significant enhancements to our test suite and minimizing needless efforts on unkillable mutants, we aim to improve our mutation testing procedure through this lab.

# A discussion of what could have been done to improve the mutation score of the test suites

The mutation coverage, which was established based on the tests we developed in labs 2 and 3, allowed us to create highly effective test suites for both the Range and DataUtilities classes. With DataUtilities nearing 81% mutation coverage, it was a difficult task to significantly enhance the coverage due to the presence of non-applicable or equivalent mutants. However, we scrutinized the mutation summaries for the statements and adopted a reverse-engineering approach to try and augment the coverage for DataUtilities. Finally, we increased the mutation score by 11 percent. A similar strategy was employed for Range to eradicate some of the surviving mutants. We tested the oringinal rangetest.java and got a 58% mutation score. We carefully looked at the result and see which mutants haven't been killed. Then we look at these alive mutants and made some test cases to kill them. Finally, we increaseed the mutation score by 10%.   In future, this same methodology can potentially be utilized to eliminate more mutants, thereby improving the mutation score.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is essential for evaluating the quality of our test suites and their effectiveness in identifying errors. By making small changes (mutations) to the software, we can test whether the current test suite can detect these changes, thereby assessing the suite's ability to catch errors.

## Advantages and Disadvantages of Mutation Testing


Mutation testing offers a powerful method for improving the quality and effectiveness of test suites in identifying errors. However, its practical application requires careful consideration of its potential drawbacks, including time, computational resources, and the handling of equivalent mutants. By addressing these challenges, development teams can leverage mutation testing to significantly enhance their software testing processes.

| Aspect                 | Advantages                                                                                     | Disadvantages                                                                                  |
|------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|
| **Automation**         | Mutation testing is automated, reducing the need for manual intervention.                      | The process can be time-intensive, potentially slowing down the development process.           |
| **Quality Assessment** | Provides a mutation score, indicating test suite quality and when to cease testing.           | The presence of equivalent mutants, which the test suite cannot detect, poses a challenge.     |
| **Error Identification** | Enhances the ability to identify hidden errors by testing the test suite's error detection capabilities. | Requires significant computational resources, which may not be feasible for all projects. |
| **Test Suite Improvement** | Encourages the improvement of the test suite's coverage and effectiveness.                   | May produce false positives, requiring additional analysis to identify valid issues.          |











# Explain your SELENUIM test case design process
## Shanzi Ye
Shanzi tested two main features on the eBay website: Providing Feedback and Getting Help. These tests simulate common user interactions with the site, verifying the functionality and user experience for feedback submission and help information retrieval.

| Feature              | Description                                                   |
|----------------------|---------------------------------------------------------------|
| Providing Feedback   | Tests the user's ability to provide feedback through the eBay website's feedback form. This includes opening the feedback form, selecting a rating, entering feedback text, and submitting the feedback. |
| Getting Help         | Tests the user's ability to search for help topics through the eBay Help and Contact page. This includes navigating to the Help page, entering search terms, executing the search, and verifying the results. |

## Zhifan Li
Zhifan conducted Selenium automated tests on the eBay website, focusing on user authentication, search functionality, and account management. These tests are designed to simulate common user interactions, such as logging in with valid credentials, searching for items using specific keywords, viewing item details, and logging out. 

| Feature                                         | Description                                                                                                 |
|-------------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| Login With  Credentials                    | Tests the user's ability to log in using valid credentials, including navigating to the sign-in page and entering user details. |
| Search With Keywords and View First Item  | Extends the search test by selecting and viewing the first item in the search results, verifying item details. |


## Sandip Mishra

Sandip tested the search bar functionality in various scenarios and the language change feature. These tests simulate user interactions to verify the search functionality with different inputs and the ability to change the website's language setting.

| Feature                             | Description                                                                |
|-------------------------------------|----------------------------------------------------------------------------|
| Search Bar Functionality            | Tests the search bar with different keywords, including large queries and no queries, ensuring accurate results are displayed. |
| Language Change Feature             | Verifies the functionality of changing the site's language setting, ensuring the site remains functional after language switches. |


## Fardin Aryan

Fardin focused on features that enhance user navigation and access: shopping by category and changing the country settings. 

| Feature                               | Description                                                                 |
|---------------------------------------|-----------------------------------------------------------------------------|
| Shop by Category with Subcategory     | Verifies the user's ability to navigate eBay’s inventory by selecting various categories and subcategories. |
| Change Country to Different Country   | Tests the functionality of the eBay site to switch to a different country version, checking for appropriate content changes. |




# Explain the use of assertions and checkpoints

Assertions are used in the scenarios we covered for eBay to confirm the final state following activities like product searches and language changes on the website. For instance, we claim that the keyword "ipad" shows in the search results heading after typing the word into the search box and clicking search, indicating the search was carried out successfully. In a similar vein, we verify that the word "支援及聯絡" (Support and Contact) is there when we switch the country option to Taiwan, indicating that the site's content has been changed to reflect the language of the chosen nation. These checkpoints are essential for verifying that every test phase yields the desired outcome, therefore guaranteeing that the functionality of the application satisfies the required specifications.

# how did you test each functionaity with different test data

## Shanzi Ye
| Test Functionality             | Scenario                                   | Description |
|--------------------------------|---------------------------------------------|-------------|
| Providing Feedback             | Positive feedback text                      | Tests the functionality of the feedback form by entering positive text to simulate a satisfied user experience. |
| Providing Feedback             | No feedback text (empty parameters)         | Verifies that the feedback form handles empty submissions correctly and provides appropriate feedback to the user. |
| Providing Feedback             | All empty parameters                        | Checks the behavior of the feedback submission when all fields are left empty, ensuring error handling and validation work. |
| Getting Help with Specifics    | Query with specific keywords ("Stolen Items") | Assesses the help section's search functionality by looking up terms related to specific issues, confirming the relevancy of search results. |
| Getting Help without Parameters| No search query                             | Tests the default state and response of the help section when no query is entered. |
| Getting Help with Random Text  | Random alphanumeric string                  | Evaluates the search function's handling of random, irrelevant input, testing the system's robustness against unexpected or non-standard queries. |

## Zhifan Li
| Functionality                             | Scenario                                  | Description |
|-------------------------------------------|-------------------------------------------|-------------|
| Login With Valid Credentials              | Normal login process                      | Validates the user's ability to log in with valid credentials using eBay's standard login flow, including optional sign-in with Google. |
| Login and Skip Additional Authentication  | Skipping optional authentication steps    | Tests the login flow when the user opts to skip additional authentication options like Google sign-in. |
| Verify Successful Login                   | Confirming user identity after login      | Ensures that after login, the system correctly displays the user's identity, confirming a successful sign-in. |
| Search With Valid Keywords                | Performing a search with common keywords  | Verifies the search functionality by entering common search terms and assessing the presence of search results. |
| Viewing First Item From Search Results    | Detailed view of a search result          | After a search, tests the functionality of viewing detailed information for the first item listed in the search results. |
| Verify Listing Details                    | Confirming details of a listed item       | Ensures that the details of a listed item, such as title and options, are present and correct. |
| Logout With Valid Credentials             | Normal logout process                     | Confirms the user's ability to log out properly and verifies the correct response of the website upon logout. |

## Sandip Mishra
| Functionality                         | Scenario                                          | Description |
|---------------------------------------|---------------------------------------------------|-------------|
| Search Bar Functionality              | Searching for a specific item (iPad)              | Verifies the search bar's ability to find items using a specific keyword and checks if the results are relevant. |
| Search with Large Query               | Attempting a search with an extensive query       | Tests the search bar's response to a large search query and whether it handles it gracefully without showing results. |
| Search with No Query                  | Triggering a search without entering any keywords | Examines how the search functionality behaves when no search terms are provided and ensures no irrelevant results are shown. |
| Language Change Interface             | Switching the interface language to French        | Confirms that the language change functionality works correctly and that the interface updates to reflect the new language choice. |
| Language Change, Search, and Revert   | Performing a search after a language change       | Checks if the search feature works correctly after the interface language has been changed and then reverts the language to English to validate consistency. |


## Fardin Aryan
| Functionality                              | Scenario                                  | Description |
|--------------------------------------------|-------------------------------------------|-------------|
| Shop by Category with Subcategory          | Navigating to a subcategory (Antiques)    | Confirms the site's navigation through categories and subcategories, and verifies the page title and breadcrumb trail for accuracy. |
| Shop by Category with Main Category        | Browsing a main category (Collectibles & Art) | Checks the functionality of shopping by main categories and ensures that relevant page titles and category descriptions appear. |
| Change Country to Different Country        | Changing the site's country to Taiwan     | Tests the ability to switch to a different country's version of the site and checks for the corresponding language and support link updates. |
| Change Country to the Same Country         | Selecting the same country (Canada)       | Ensures the site does not redirect or change unnecessarily when selecting the country version that is already active. |

# Discuss advantages and disadvantages of Selenium vs. Sikulix

Both Selenium and SikuliX are popular tools in the automation testing landscape, each offering unique advantages and facing certain limitations. Below is a comparison to help understand their strengths and weaknesses.

## Selenium

Selenium is widely used for automating web browsers, providing a robust framework for testing web applications across different browsers and platforms.

### Advantages and Disadvantages

| Aspect             | Advantages                                                                 | Disadvantages                                                 |
|--------------------|----------------------------------------------------------------------------|---------------------------------------------------------------|
| **Support**        | Extensive cross-platform and cross-browser support.                        | Limited to the testing of web applications only.              |
| **Versatility**    | Highly versatile for web testing scenarios.                               |                                                               |
| **Community**      | Large community support and extensive documentation.                       |                                                               |

## SikuliX

SikuliX leverages visual recognition to automate actions on both web and desktop applications, making it useful for a variety of testing scenarios beyond traditional web testing.

### Advantages and Disadvantages

| Aspect                 | Advantages                                                                                  | Disadvantages                                                        |
|------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------------------------|
| **Capability**         | Can automate Flash objects, providing a unique advantage.                                   | Faces challenges with cross-browser testing.                        |
| **Utility**            | Extends automation capabilities to desktop applications, broadening its utility.            |                                                                      |
| **Versatility**        | Useful for scenarios where traditional object identification fails.                         |                                                                      |

## Conclusion

Selenium and SikuliX offer different sets of features that cater to various testing needs. Selenium's strength lies in its extensive support for web application testing across a multitude of browsers and platforms. On the other hand, SikuliX's ability to automate Flash objects and desktop applications provides a broader scope of testing beyond web applications. However, the choice between Selenium and SikuliX should be based on the specific requirements of the testing project, considering the advantages and limitations of each tool.
# How the team work/effort was divided and managed
Our team prioritized equitable workload distribution and active collaboration for this assignment. Each member contributed significantly, ensuring a balanced effort across the board. Below is a detailed breakdown of our work division:

## Work Distribution

### Part 1: Enhancing Mutation Scores and Reporting

- **Group 1: Shanzi and Fardin**: Tasked with improving the mutation score of `RangeTest.java`. Group 1's responsibilities also include drafting the associated report, detailing the strategies employed and the outcomes achieved.

- **Group2: Zhifan and Sandip**: Focused on elevating the mutation score of `DataUtility.java`. Similar to their group 1, group 2 are also in charge of composing the report related to their task, encompassing both the methodology used and the results obtained.

### Part 2: Case Testing Requirements

- As per assignment requirements, each team member was required to test at least two cases. Adhering to this guideline, everyone successfully executed two case tests, demonstrating our collective commitment to fulfilling the project requirements comprehensively.





# Difficulties encountered, challenges overcome, and lessons learned

We had several difficulties when working on Lab 4, mostly related to comprehending the objectives of the task and preparing the PITest environment. One of the biggest obstacles was the ambiguous instructions, which made it difficult to understand and took a lot of time to complete the job. Further impeding our work were technical issues with PITest, which sometimes prevented it from producing summaries and necessitated several restarts. Our time was mostly taken up by these problems, which hindered our productivity and made it harder for us to comprehend the lab activities.In spite of these challenges, we worked on the assignment and figure out the solution. We discovered the value of perseverance and cooperation and this assignment improves our troubleshooting abilities.

# Comments/feedback on the lab itself

Our understanding and proficiency in software testing were enhanced by the insightful experience of the Web App and Mutation Testing Lab. Although it is a little difficult at first due to a lack of thorough instructions, working with PIT Mutation and Selenium turned out to be immensely informative. One of the best parts of the lab was working as a team to overcome the more challenging parts. We enjoyed the process even though we had to deal with some challenging situations that put our comprehension to the test. In the future, a greater range of examples, better beginning support, and more detailed instructions would all significantly improve the lab's learning experience.
